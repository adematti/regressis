{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging systematic mitigation: the QSO case\n",
    "\n",
    "**author:** Edmond Chaussidon (CEA Saclay)\n",
    "\n",
    "**mail:** edmond.chaussidon@cea.fr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from regressis import PhotometricDataFrame, Regressor, DR9Footprint, setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('Notebook')\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000001.18] 22-01-03 15:09  Footprint            INFO     Load DR9 footprint with mask_lmc=True, clear_south=True, mask_around_des=True and desi_cut=False\n",
      "[000001.23] 22-01-03 15:09  DataFrame            INFO     version: SV3 -- tracer: QSO -- region: ['North', 'South', 'Des']\n",
      "[000001.23] 22-01-03 15:09  DataFrame            INFO     Read ../regressis/tests/test_case_qso/pixweight-dr9-256.fits.\n",
      "[000001.57] 22-01-03 15:09  DataFrame            INFO     Read ../regressis/tests/test_case_qso/sagittarius_stream_256.npy\n",
      "[000001.62] 22-01-03 15:09  DataFrame            INFO     Sanity check: number of NaNs in features: 0\n",
      " \n",
      "[000001.63] 22-01-03 15:09  DataFrame            INFO     Read ../regressis/tests/test_case_qso/SV3_QSO_256.npy\n",
      "[000001.64] 22-01-03 15:09  DataFrame            INFO     Do not find corresponding fracarea map --> use FRACAREA_12290 as default fracarea\n",
      "[000001.64] 22-01-03 15:09  DataFrame            INFO     Read ../regressis/tests/test_case_qso/pixweight-dr9-256.fits\n",
      " \n",
      "[000002.64] 22-01-03 15:09  DataFrame            INFO     The considered footprint represents 100.00% of the DR9 footprint\n",
      "[000002.64] 22-01-03 15:09  DataFrame            INFO     They are 9069 pixels which will be not used for the training i.e. 2.47% ot the considered footprint\n",
      "[000004.00] 22-01-03 15:09  Footprint            INFO     Use (R.A., Dec.) box: [120, 240, 32.2, 40] to compute mean density\n",
      "[000004.08] 22-01-03 15:09  DataFrame            INFO       ** North: 16.02 -- 1.0000 -- 1.0623\n",
      "[000005.49] 22-01-03 15:09  Footprint            INFO     Use (R.A., Dec.) box: [120, 240, 24, 32.2] to compute mean density\n",
      "[000005.56] 22-01-03 15:09  DataFrame            INFO       ** South: 16.08 -- 1.0000 -- 1.0301\n",
      "[000007.00] 22-01-03 15:09  Footprint            INFO     No specific area is used to compute mean density\n",
      "[000007.01] 22-01-03 15:09  DataFrame            INFO       ** Des: 15.32 -- 1.0000 -- 1.0000\n",
      " \n"
     ]
    }
   ],
   "source": [
    "version, tracer, suffix_tracer = 'SV3', 'QSO', ''\n",
    "dr9_footprint = DR9Footprint(256, mask_lmc=True, clear_south=True, mask_around_des=True, desi_cut=False)\n",
    "\n",
    "param = dict()\n",
    "param['data_dir'] = '../regressis/tests/test_case_qso'\n",
    "param['output_dir'] = None\n",
    "param['use_median'] = False\n",
    "param['use_new_norm'] = True\n",
    "param['region'] = ['North', 'South', 'Des']\n",
    "\n",
    "dataframe = PhotometricDataFrame(version, tracer, dr9_footprint, suffix_tracer, **param)\n",
    "dataframe.set_features()\n",
    "print(\" \")\n",
    "\n",
    "dataframe.set_targets()\n",
    "print(\" \")\n",
    "\n",
    "dataframe.build(selection_on_fracarea=True)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000007.02] 22-01-03 15:09  Regressor            INFO     We use the set: ['STARDENS', 'EBV', 'STREAM', 'PSFDEPTH_G', 'PSFDEPTH_R', 'PSFDEPTH_Z', 'PSFDEPTH_W1', 'PSFDEPTH_W2', 'PSFSIZE_G', 'PSFSIZE_R', 'PSFSIZE_Z']\n",
      "[000007.02] 22-01-03 15:09  root                 WARNING  do not use kfold training --> TAKE CARE\n",
      " \n",
      "[000008.43] 22-01-03 15:09  Regressor            INFO       ** North :\n",
      "[000008.48] 22-01-03 15:09  Regressor            INFO         --> Sample size North: 96329 -- Total Sample Size: 358139 -- Training Fraction: 26.90%\n",
      "[000008.48] 22-01-03 15:09  Regressor            INFO         --> use Kfold training ? False\n",
      "[000008.48] 22-01-03 15:09  Regressor            INFO         --> Engine: LINEAR with params: {}\n",
      "[000008.49] 22-01-03 15:09  Regressor            INFO               --> We normalize and center all features (except the STREAM) on the training footprint\n",
      "[000008.62] 22-01-03 15:09  Regressor            INFO               --> Mean of Mean and Std on the fold-training features : 0.0000 -- 1.00\n",
      "[000008.62] 22-01-03 15:09  Regressor            INFO               --> The training is done with sample_weight=1/np.sqrt(Y_train)\n",
      "[000010.11] 22-01-03 15:09  Regressor            INFO       ** South :\n",
      "[000010.15] 22-01-03 15:09  Regressor            INFO         --> Sample size South: 175088 -- Total Sample Size: 358139 -- Training Fraction: 48.89%\n",
      "[000010.15] 22-01-03 15:09  Regressor            INFO         --> use Kfold training ? False\n",
      "[000010.15] 22-01-03 15:09  Regressor            INFO         --> Engine: LINEAR with params: {}\n",
      "[000010.16] 22-01-03 15:09  Regressor            INFO               --> We normalize and center all features (except the STREAM) on the training footprint\n",
      "[000010.34] 22-01-03 15:09  Regressor            INFO               --> Mean of Mean and Std on the fold-training features : 0.0000 -- 1.00\n",
      "[000010.34] 22-01-03 15:09  Regressor            INFO               --> The training is done with sample_weight=1/np.sqrt(Y_train)\n",
      "[000011.96] 22-01-03 15:09  Regressor            INFO       ** Des :\n",
      "[000012.01] 22-01-03 15:09  Regressor            INFO         --> Sample size Des: 86722 -- Total Sample Size: 358139 -- Training Fraction: 24.21%\n",
      "[000012.01] 22-01-03 15:09  Regressor            INFO         --> use Kfold training ? False\n",
      "[000012.01] 22-01-03 15:09  Regressor            INFO         --> Engine: LINEAR with params: {}\n",
      "[000012.02] 22-01-03 15:09  Regressor            INFO               --> We normalize and center all features (except the STREAM) on the training footprint\n",
      "[000012.17] 22-01-03 15:09  Regressor            INFO               --> Mean of Mean and Std on the fold-training features : -0.0000 -- 1.00\n",
      "[000012.17] 22-01-03 15:09  Regressor            INFO               --> The training is done with sample_weight=1/np.sqrt(Y_train)\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "regressor = Regressor(dataframe, engine='LINEAR', compute_permutation_importance=True, overwrite_regression=True, n_jobs=6, seed=123, save_regressor=False, use_kfold=False)\n",
    "print(\" \")\n",
    "\n",
    "regressor.make_regression()\n",
    "print(\" \")\n",
    "\n",
    "w_sys = regressor.build_w_sys_map(savemap=False, savedir=param['output_dir'])\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.plot_maps_and_systematics(max_plot_cart=400) --> il faut reussir a afficher les cartes --< mettre l'option show dans le code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not param['output_dir'] is None:\n",
    "    \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    logger.info('Load precompute systematic weights and compare the current computation')\n",
    "#    w_sys_test = np.load(os.path.join(param['data_dir'], 'SV3_QSO_imaging_weight_256.npy'))\n",
    "#    mask = ~np.isnan(w_sys)\n",
    "#    assert np.allclose(w_sys[mask], w_sys_test[mask]), \"The computation of systematic weights in test case gives bad result, please do not change any parameter in tests.py\"\n",
    "#    logger.info('Test is complete without any error :) !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il faut faire un notebook qui reprend l'exemple facile --> QSO main par exemple\n",
    "\n",
    "qui montre comment on utilise pas les etoiles ec ...\n",
    "\n",
    "+ afficher les dessins jolies\n",
    "\n",
    "+ montrer comment on fait pour recuperer les poids a prtir d'un catalog grace au ra, dec --> mettre le code dans regressis\n",
    "\n",
    "+ mettre le style matplotlib qui va vbien !!\n",
    "\n",
    "--> dire attention au poids des fichiers !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desi_py3",
   "language": "python",
   "name": "desi_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
